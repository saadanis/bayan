# -*- coding: utf-8 -*-
"""Bayan Relevance Classification

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V71MEIGXJAirCZYryooZTQDWhWHX8XuG

## Setup
"""

import torch

# If there's a GPU available...
if torch.cuda.is_available():    

    # Tell PyTorch to use the GPU.    
    device = torch.device("cuda")

    print('There are %d GPU(s) available.' % torch.cuda.device_count())

    print('We will use the GPU:', torch.cuda.get_device_name(0))
    !nvidia-smi

# If not...
else:
    print('No GPU available, using the CPU instead.')
    device = torch.device("cpu")

!pip install transformers
!pip install farasapy==0.0.14
!pip install pyarabic==0.6.14
!git clone https://github.com/aub-mind/arabert
!pip install sentencepiece==0.1.96
!pip install datasets

from datasets import load_dataset, load_metric
from transformers import AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification
from transformers import TrainingArguments, Trainer
from arabert.preprocess import ArabertPreprocessor
import numpy as np
from sklearn.metrics import (accuracy_score, classification_report,
                             confusion_matrix, f1_score, precision_score,
                             recall_score)

"""Set up constants.

"""

DIRECT_SCORE = 0
RELATED_SCORE = 1
IRRELEVANT_SCORE = 2

"""## Prepare for Training

Initialize tokenizer, data collator, and AraBERT preprocessor.
"""

checkpoint = "aubmindlab/bert-base-arabertv2"

tokenizer = AutoTokenizer.from_pretrained(checkpoint)

data_collator = DataCollatorWithPadding(tokenizer)

arabert_preprocessor = ArabertPreprocessor(checkpoint)

"""Load dataset from JSON file and split into a training and testing sets. *(You need to upload the `semeval_dataset.json` file to your Drive first, and then mount Drive to this notebook.)*"""

semeval_dataset = load_dataset(
    'json',
    data_files={'train': '/content/drive/MyDrive/semeval_dataset_train.json',
                'dev': '/content/drive/MyDrive/semeval_dataset_dev.json',
                'test': '/content/drive/MyDrive/semeval_dataset_test.json'},
    field='data')
print(semeval_dataset.column_names)

"""Create an AraBERT preprocessing function and preprocess the dataset."""

def preprocess_for_arabert(example):
  example['question'] = arabert_preprocessor.preprocess(example['question'])
  example['answer'] = arabert_preprocessor.preprocess(example['answer'])
  if 'label' in example:
    if example['label'] == "direct":
      example['label'] = 0
    elif example['label'] == "related":
      example['label'] = 1
    elif example['label'] == "irrelevant":
      example['label'] = 2

  return example

preprocessed_dataset = semeval_dataset.map(preprocess_for_arabert)

"""Create a tokenization function and tokenize the dataset."""

def tokenize_function(examples):
  return tokenizer(examples['question'], examples['answer'])

tokenized_datasets = preprocessed_dataset.map(tokenize_function, batched=True)

"""Check to see if it worked."""

print(tokenizer.decode(tokenized_datasets['train']['input_ids'][0]))

"""## Training

Load AraBERT model.
"""

model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=3)

"""Specify training arguments."""

training_args = TrainingArguments(
    "test-trainer",
    num_train_epochs= 10,
    learning_rate = 2e-5,
    evaluation_strategy = 'epoch',
    save_strategy = 'epoch',
    load_best_model_at_end = True, # this allows to automatically get the best model at the end based on whatever metric we want
    metric_for_best_model = 'macro_f1',
    # per_device_train_batch_size = 4, # up to 64 on 16GB with max len of 128, was 16
    # per_device_eval_batch_size = 16,
    # gradient_accumulation_steps = 15, # use this to scale batch size without needing more memory
)

def compute_metrics(p): #p should be of type EvalPrediction
  preds = np.argmax(p.predictions, axis=1)
  assert len(preds) == len(p.label_ids)
  #print(classification_report(p.label_ids,preds))
  #print(confusion_matrix(p.label_ids,preds))
  macro_f1 = f1_score(p.label_ids,preds,average='macro')
  #macro_precision = precision_score(p.label_ids,preds,average='macro')
  #macro_recall = recall_score(p.label_ids,preds,average='macro')
  acc = accuracy_score(p.label_ids,preds)
  return {       
      'macro_f1' : macro_f1,
      'accuracy': acc
  }

"""Start training. *(Evaluation not setup yet.)*"""

trainer = Trainer(
    model,
    training_args,
    train_dataset=tokenized_datasets['train'],
    eval_dataset=tokenized_datasets['dev'],
    data_collator=data_collator,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics
)

trainer.train()

"""Save trained model."""

label_map = {
    "direct": 0,
    "related": 1,
    "irrelevant": 2
}
inv_label_map = { v:k for k, v in label_map.items() }

trainer.model.config.label2id = label_map
trainer.model.config.id2label = inv_label_map
trainer.save_model("saved_model_new")

"""Save model to Drive for persistance."""

!cp -r /content/saved_model_new /content/drive/MyDrive

from huggingface_hub import notebook_login
notebook_login()

from huggingface_hub import HfApi
api = HfApi()

# api.create_repo?

api.create_repo (
    repo_id = "saadanis", # The name of our repository, by default under your user
    private = True, # Whether the repo should be public or private
    repo_type = "model" # The type of repository, such as "model", "space", "dataset"
)

"""## Predict

Load saved model from Drive if it already exists.
"""

!cp -r /content/drive/MyDrive/saved_model_new /content

"""Load tokenizer and model from the saved model."""

tokenizer = AutoTokenizer.from_pretrained("saved_model_new")
model = AutoModelForSequenceClassification.from_pretrained("saved_model_new")

classes = ["direct", "related", "irrelevant"]

"""Predict the relevancy of the question and answer."""

question= "هل يجوز الحج عن شخص متوفى شنقاً؟"
answer= "فإن كان المراد أن الشخص المتوفى شنق نفسه فهذا يعتبر منتحراً، والانتحار جريمة شنيعة توعد الله صاحبها، ولكنه إذا كان مات على الإسلام يشرع الحج عنه، بل يجب إذا كان اقتدر على الحج ولم يحج وترك مالاً يمكن أن يحج عنه به، وهذا هو مذهب الشافعية والحنابلة وهو الراجح، وقال الأحناف والمالكية لا يجب الحج عنه، وراجع للبسط في الموضوع الفتاوى ذات الأرقام التالية: ، ، ، ، ، . والله أعلم."

tokenized_example = tokenizer(question, answer, return_tensors="pt")

classification_logits = model(**tokenized_example).logits

classification_results = torch.softmax(classification_logits, dim=1).tolist()[0]

for i in range(len(classes)):
    print(f"{classes[i]}: {round(classification_results[i]*100, 2)}%")

"""## Test

Load saved model from Drive if it already exists.
"""

!cp -r /content/drive/MyDrive/saved_model /content

"""Load tokenizer and model from the saved model."""

tokenizer = AutoTokenizer.from_pretrained("saved_model")
model = AutoModelForSequenceClassification.from_pretrained("saved_model")

classes = ["direct", "related", "irrelevant"]

"""### Pointwise Testing (Outdated)

Test precision, recall, and F1 for each isolated query-answer pair.
"""

results = []

for item in tokenized_datasets['test']:
  tokenized_item = tokenizer(item['question'], item['answer'], return_tensors='pt')
  classification_logits = model(**tokenized_item).logits
  classification_results = torch.softmax(classification_logits, dim=1).tolist()[0]

  prediction_index = classification_results.index(max(classification_results))
  results.append([prediction_index, item['label']])

print(results)

import json

with open("results.json", "w") as f:
  json.dump(results, f)

r_pred = []
r_true = []

for result in results:
  r_pred.append(result[0])
  r_true.append(result[1])

print(r_pred)
print(r_true)

from sklearn import metrics

print(metrics.classification_report(r_true, r_pred, digits=3))

"""### Listwise Testing

"""

from sklearn.metrics import ndcg_score

idcg = []
dcg = []

for i in range(int(len(tokenized_datasets['test'])/5)):
  print(f"{(i*5)+1}/{len(tokenized_datasets['test'])}")
  _idcg = []
  _dcg = []
  for j in range(5):
    item = tokenized_datasets['test'][(i*5)+j]
    _idcg.append(item['label'])
    tokenized_item = tokenizer(item['question'], item['answer'], return_tensors='pt')
    classification_logits = model(**tokenized_item).logits
    classification_results = torch.softmax(classification_logits, dim=1).tolist()[0]

    cl_index = classification_results.index(max(classification_results))
    if cl_index == 0:
      _dcg.append(DIRECT_SCORE)
    elif cl_index == 1:
      _dcg.append(RELATED_SCORE)
    elif cl_index == 2:
      _dcg.append(IRRELEVANT_SCORE)
  idcg.append(_idcg)
  dcg.append(_dcg)

print(idcg)
print(dcg)

ndcg_score(np.asarray(idcg),np.asarray(dcg))